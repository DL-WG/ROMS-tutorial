{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PC-AE_FPTC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPuGLSdE97UmhiSXytBPauH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DL-WG/ROMS-tutorial/blob/main/PC_AE_FPTC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDxE--pZ1T1z"
      },
      "source": [
        "## Flow past the cylinder with PC-based Autoencoder\n",
        "## PREMIERE tutorial on reduced-order models\n",
        "## Author: César Quilodrán-Casas\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow.keras as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend\n",
        "import eofs\n",
        "from eofs.standard import Eof\n",
        "\n",
        "plt.rcParams.update({'font.size': 10})\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)\n",
        "plt.rc('axes', labelsize=10)\n",
        "\n",
        "#Load vtk packages\n",
        "import vtk\n",
        "import sys, os\n",
        "sys.path.append('/Users/cequilod/')\n",
        "import vtktools\n",
        "\n",
        "directory = '/Users/cequilod/ROMS-tutorial/'\n",
        "\n",
        "#Load data\n",
        "vel_x = np.load(directory + 'vx_field.npy')\n",
        "vel_y = np.load(directory + 'vy_field.npy')\n",
        "\n",
        "modelData = np.concatenate([vel_x, vel_y], 1)\n",
        "\n",
        "#Add PCA\n",
        "#Standardise data\n",
        "meanData = np.mean(modelData, axis = 0)\n",
        "stdData = np.std(modelData)\n",
        "modelDataScaled = (modelData - meanData)/stdData\n",
        "\n",
        "solver = Eof(modelDataScaled)\n",
        "\n",
        "varianceCumulative = np.cumsum(solver.varianceFraction())\n",
        "eigenvalues = solver.eigenvalues()\n",
        "pcs = solver.pcs()\n",
        "eof = solver.eofs()\n",
        "\n",
        "#Scale data\n",
        "modelMin = np.min(pcs, 0)\n",
        "modelMax = np.max(pcs, 0)\n",
        "\n",
        "def scaler(x, xmin, xmax, min, max):\n",
        "    scale = (max - min)/(xmax - xmin)\n",
        "    xScaled = scale*x + min - xmin*scale\n",
        "    return xScaled\n",
        "\n",
        "pcsScaled = scaler(pcs, modelMin, modelMax, 0, 1)\n",
        "\n",
        "nFeatures = pcsScaled.shape[1]\n",
        "nSnapshots = pcsScaled.shape[0]\n",
        "\n",
        "#Get training and test data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(pcsScaled, pcsScaled, test_size=0.1, shuffle=True, random_state=42)\n",
        "\n",
        "#Define model\n",
        "input_enc = tf.Input(shape=(nFeatures))\n",
        "enc = tf.layers.Dense(64)(input_enc)\n",
        "enc = tf.layers.Dense(32)(enc)\n",
        "enc_output = tf.layers.Dense(16)(enc)\n",
        "\n",
        "input_dec = tf.Input(shape=(16))\n",
        "dec = tf.layers.Dense(32)(input_dec)\n",
        "dec = tf.layers.Dense(64)(dec)\n",
        "dec = tf.layers.Dense(nFeatures, activation='sigmoid')(dec)\n",
        "\n",
        "#Encoder model\n",
        "enc_model = tf.Model(input_enc, enc_output)\n",
        "enc_model.summary()\n",
        "#Decoder model\n",
        "dec_model = tf.Model(input_dec, dec)\n",
        "dec_model.summary()\n",
        "#ae model\n",
        "ae_model = tf.Model(input_enc, dec_model(enc_output))\n",
        "\n",
        "ae_model.compile(loss='mse', optimizer='adam')\n",
        "history = ae_model.fit(X_train, y_train, epochs=100, batch_size=256, verbose=2, validation_data = (X_test, y_test), shuffle = True)\n",
        "plt.plot(ae_model.predict(pcsScaled)[:, 0])\n",
        "plt.plot(pcsScaled[:, 0])\n",
        "\n",
        "#tf.models.save_model(ae_model, directory + 'ae_model')\n",
        "#tf.models.save_model(enc_model, directory + 'enc_model')\n",
        "#tf.models.save_model(dec_model, directory + 'dec_model')\n",
        "\n",
        "ae_model = tf.models.load_model(directory + 'ae_model')\n",
        "enc_model = tf.models.load_model(directory + 'enc_model')\n",
        "dec_model = tf.models.load_model(directory + 'dec_model')\n",
        "\n",
        "#Plot losses\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "#Prediction with AE\n",
        "ae_prediction = ae_model.predict(pcsScaled)\n",
        "def inverseScaler(xscaled, xmin, xmax, min, max):\n",
        "    scale = (max - min) / (xmax - xmin)\n",
        "    xInv = (xscaled/scale) - (min/scale) + xmin\n",
        "    return xInv\n",
        "\n",
        "ae_prediction = inverseScaler(ae_prediction, modelMin, modelMax, 0, 1)\n",
        "ae_prediction = np.matmul(ae_prediction, eof)*stdData + meanData\n",
        "\n",
        "#Predicted velocities\n",
        "vel_x_pred = ae_prediction[:, :vel_x.shape[1]]\n",
        "vel_y_pred = ae_prediction[:, vel_x.shape[1]:vel_y.shape[1]*2]\n",
        "\n",
        "#Vector expects a third field, since this is 2D then vel_z = 0\n",
        "vel_z = np.zeros((vel_x_pred.shape[0], vel_x.shape[1]))\n",
        "\n",
        "vel_pred = np.zeros((vel_x_pred.shape[0], vel_x_pred.shape[1], 3))\n",
        "vel_pred[:, :, 0] = vel_x_pred\n",
        "vel_pred[:, :, 1] = vel_y_pred\n",
        "vel_pred[:, :, 2] = vel_z\n",
        "\n",
        "#Reconstruction onto .vtu files\n",
        "for i in range(vel_pred.shape[0]):\n",
        "    filename = directory + str(i) + '.vtu'\n",
        "    ug = vtktools.vtu(filename)\n",
        "    ug.AddVectorField('Recon_PCAE', vel_pred[i, :, :])\n",
        "    # ug.AddScalarField('WGANAE_Tracer_8', np.squeeze(ae_prediction))\n",
        "    # ug.AddScalarField('PC_Tracer_8', np.squeeze(pc_trun))\n",
        "    ug.Write(directory + str(i) + '.vtu')\n",
        "    print(i)\n",
        "\n",
        "#Paraview"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}